{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbae7e72",
   "metadata": {},
   "source": [
    "\n",
    "# 🧪 Deepfake Detection — Jupyter Notebook (Keras + Gradio)\n",
    "\n",
    "This notebook lets you **train** and **demo** a Deepfake Detector end‑to‑end:\n",
    "\n",
    "- ✅ Dataset loaders (train/val split via `flow_from_directory`)\n",
    "- ✅ Choice of **Simple CNN** or **EfficientNetB0** (transfer learning)\n",
    "- ✅ Saves `models/deepfake_detector_keras.h5` and `models/labels.json`\n",
    "- ✅ Quick evaluation & **threshold** suggestion\n",
    "- ✅ **Gradio UI** for uploads and **webcam** (if supported)\n",
    "- ✅ **Mock Mode** fallback if no model is loaded\n",
    "\n",
    "> **Dataset format (binary classes):**\n",
    ">\n",
    "> ```\n",
    "> data/dataset/\n",
    "> ├── real/\n",
    "> └── fake/\n",
    "> ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87870e72",
   "metadata": {},
   "source": [
    "## 1) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e8cfaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.19.0\n",
      "GPU Available: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# If needed, install packages (uncomment as necessary)\n",
    "# %pip install tensorflow==2.15.0 pillow numpy opencv-python-headless gradio==4.44.0 scikit-learn\n",
    "\n",
    "import os, json, math, time, pathlib, typing, warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fff575",
   "metadata": {},
   "source": [
    "## 2) Configure paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc497dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR: d:\\Mtech\\Research paper\\DeepFake Detection\\Minor Version\n",
      "DATA_DIR exists: True\n",
      "MODEL_DIR: d:\\Mtech\\Research paper\\DeepFake Detection\\Minor Version\\models\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Change these if your structure differs\n",
    "BASE_DIR = Path.cwd()\n",
    "DATA_DIR = BASE_DIR / \"data\" / \"dataset\"   # expects subfolders: real/, fake/\n",
    "MODEL_DIR = BASE_DIR / \"models\"\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_PATH = MODEL_DIR / \"deepfake_detector_keras.h5\"\n",
    "LABELS_PATH = MODEL_DIR / \"labels.json\"\n",
    "\n",
    "IMG_SIZE = (128, 128)   # can override to (224,224) for EfficientNet\n",
    "BATCH = 64\n",
    "VAL_SPLIT = 0.2\n",
    "EPOCHS = 8            # start with 8–15, tune later\n",
    "\n",
    "print(\"BASE_DIR:\", BASE_DIR)\n",
    "print(\"DATA_DIR exists:\", DATA_DIR.exists())\n",
    "print(\"MODEL_DIR:\", MODEL_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a612286",
   "metadata": {},
   "source": [
    "## 3) Data generators (train/val split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deed1d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16002 images belonging to 2 classes.\n",
      "Found 4000 images belonging to 2 classes.\n",
      "Saved class indices: {'Fake': 0, 'Real': 1}\n",
      "labels.json: d:\\Mtech\\Research paper\\DeepFake Detection\\Minor Version\\models\\labels.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not DATA_DIR.exists():\n",
    "    raise SystemExit(f\"Dataset folder not found: {DATA_DIR}. Put images under real/ and fake/ subfolders.\")\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1/255.0,\n",
    "    validation_split=VAL_SPLIT,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.02,\n",
    "    height_shift_range=0.02,\n",
    "    zoom_range=0.5,\n",
    ")\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    DATA_DIR.as_posix(),\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"training\",\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_gen = train_datagen.flow_from_directory(\n",
    "    DATA_DIR.as_posix(),\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"validation\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Save class indices for later (UI needs to know which class is index 1)\n",
    "with open(LABELS_PATH, \"w\") as f:\n",
    "    json.dump(train_gen.class_indices, f)\n",
    "print(\"Saved class indices:\", train_gen.class_indices)\n",
    "print(\"labels.json:\", LABELS_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea13185",
   "metadata": {},
   "source": [
    "## 4) Choose model: Simple CNN or EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a71f24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,569</span> (396.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101,569\u001b[0m (396.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,569</span> (396.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,569\u001b[0m (396.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "USE_EFFICIENTNET = False   # <-- flip to True for transfer learning\n",
    "\n",
    "def build_simple_cnn(input_shape=(128,128,3)):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(inputs)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = models.Model(inputs, outputs)\n",
    "    model.compile(optimizer=optimizers.Adam(1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def build_efficientnet_b0(input_shape=(224,224,3)):\n",
    "    from tensorflow.keras.applications import EfficientNetB0\n",
    "    from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "    base = EfficientNetB0(include_top=False, input_shape=input_shape, weights=\"imagenet\")\n",
    "    base.trainable = False  # freeze first stage\n",
    "\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = preprocess_input(inputs)\n",
    "    x = base(x, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.35)(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = models.Model(inputs, outputs)\n",
    "    model.compile(optimizer=optimizers.Adam(1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# pick model\n",
    "if USE_EFFICIENTNET:\n",
    "    IMG_SIZE = (224,224)\n",
    "    # re-build generators with new image size\n",
    "    train_gen = train_datagen.flow_from_directory(\n",
    "        DATA_DIR.as_posix(),\n",
    "        target_size=IMG_SIZE, batch_size=BATCH, class_mode=\"binary\", subset=\"training\", shuffle=True\n",
    "    )\n",
    "    val_gen = train_datagen.flow_from_directory(\n",
    "        DATA_DIR.as_posix(),\n",
    "        target_size=IMG_SIZE, batch_size=BATCH, class_mode=\"binary\", subset=\"validation\", shuffle=False\n",
    "    )\n",
    "    model = build_efficientnet_b0(input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "else:\n",
    "    model = build_simple_cnn(input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f020cb2",
   "metadata": {},
   "source": [
    "## 5) Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9880549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5356 - loss: 0.6904"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 1s/step - accuracy: 0.5469 - loss: 0.6879 - val_accuracy: 0.6315 - val_loss: 0.6605\n",
      "Epoch 2/8\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 489ms/step - accuracy: 0.5589 - loss: 0.6838 - val_accuracy: 0.5817 - val_loss: 0.6702\n",
      "Epoch 3/8\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step - accuracy: 0.5594 - loss: 0.6828"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 478ms/step - accuracy: 0.5614 - loss: 0.6820 - val_accuracy: 0.6342 - val_loss: 0.6710\n",
      "Epoch 4/8\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - accuracy: 0.5689 - loss: 0.6812"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 485ms/step - accuracy: 0.5736 - loss: 0.6789 - val_accuracy: 0.6400 - val_loss: 0.6579\n",
      "Epoch 5/8\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - accuracy: 0.5718 - loss: 0.6784"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 503ms/step - accuracy: 0.5786 - loss: 0.6759 - val_accuracy: 0.6658 - val_loss: 0.6456\n",
      "Epoch 6/8\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - accuracy: 0.5872 - loss: 0.6721"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 505ms/step - accuracy: 0.5934 - loss: 0.6675 - val_accuracy: 0.6898 - val_loss: 0.6092\n",
      "Epoch 7/8\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step - accuracy: 0.6137 - loss: 0.6562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 512ms/step - accuracy: 0.6098 - loss: 0.6586 - val_accuracy: 0.7063 - val_loss: 0.6029\n",
      "Epoch 8/8\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 518ms/step - accuracy: 0.6110 - loss: 0.6592 - val_accuracy: 0.6952 - val_loss: 0.6120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: d:\\Mtech\\Research paper\\DeepFake Detection\\Minor Version\\models\\deepfake_detector_keras.h5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ckpt = callbacks.ModelCheckpoint(MODEL_PATH.as_posix(), monitor=\"val_accuracy\", save_best_only=True, mode=\"max\")\n",
    "es = callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=3, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[ckpt, es],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.save(MODEL_PATH.as_posix())\n",
    "print(\"Saved model to:\", MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ed3cc7",
   "metadata": {},
   "source": [
    "## 6) Quick evaluation & threshold suggestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adb3e7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class index 1 is: Real\n",
      "Suggested threshold: 0.70 (F1=0.329)\n",
      "[[1778  222]\n",
      " [1958   42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.48      0.89      0.62      2000\n",
      "        Real       0.16      0.02      0.04      2000\n",
      "\n",
      "    accuracy                           0.46      4000\n",
      "   macro avg       0.32      0.46      0.33      4000\n",
      "weighted avg       0.32      0.46      0.33      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "val_gen.reset()\n",
    "p1 = model.predict(val_gen, verbose=0).ravel()  # prob of class index 1\n",
    "y_true = val_gen.classes\n",
    "\n",
    "# Load mapping and infer which class is index 1\n",
    "with open(LABELS_PATH, \"r\") as f:\n",
    "    idx = json.load(f)  # e.g., {'fake': 0, 'real': 1}\n",
    "inv = {v:k for k,v in idx.items()}\n",
    "class1 = inv.get(1, None)\n",
    "print(\"Class index 1 is:\", class1)\n",
    "\n",
    "# p(fake) depends on what class 1 represents\n",
    "if class1 and class1.lower() == \"real\":\n",
    "    p_fake = 1.0 - p1\n",
    "else:\n",
    "    p_fake = p1  # class 1 is 'fake' or unknown mapping\n",
    "\n",
    "ths = np.linspace(0.3, 0.7, 41)\n",
    "best_f1, best_th = -1, 0.5\n",
    "for th in ths:\n",
    "    y_hat = (p_fake >= th).astype(int)\n",
    "    f1 = f1_score(y_true, y_hat, average=\"macro\")\n",
    "    if f1 > best_f1:\n",
    "        best_f1, best_th = f1, th\n",
    "\n",
    "print(f\"Suggested threshold: {best_th:.2f} (F1={best_f1:.3f})\")\n",
    "print(confusion_matrix(y_true, (p_fake >= best_th).astype(int)))\n",
    "print(classification_report(y_true, (p_fake >= best_th).astype(int), target_names=[inv.get(0,'class0'), inv.get(1,'class1')]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea219b0",
   "metadata": {},
   "source": [
    "## 7) Gradio demo (upload & webcam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "989bf1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\loq\\anaconda3\\lib\\site-packages (4.12.0.88)\n",
      "Collecting numpy<2.3.0,>=2 (from opencv-python)\n",
      "  Using cached numpy-2.2.6-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Using cached numpy-2.2.6-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "Successfully installed numpy-2.2.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\LOQ\\anaconda3\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\LOQ\\anaconda3\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.2.6 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.6 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
      "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio==4.44.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (4.44.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (4.2.0)\n",
      "Requirement already satisfied: fastapi<1.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (0.116.1)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (0.6.1)\n",
      "Requirement already satisfied: gradio-client==1.3.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (1.3.0)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (0.27.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (0.29.3)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (6.5.2)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\loq\\appdata\\roaming\\python\\python312\\site-packages (from gradio==4.44.0) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\loq\\appdata\\roaming\\python\\python312\\site-packages (from gradio==4.44.0) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (3.9.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (2.2.6)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (3.11.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (24.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (2.2.2)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (10.4.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (2.8.2)\n",
      "Requirement already satisfied: pydub in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (6.0.1)\n",
      "Requirement already satisfied: ruff>=0.2.2 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (0.12.8)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (4.11.0)\n",
      "Requirement already satisfied: urllib3~=2.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (2.5.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (0.35.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio-client==1.3.0->gradio==4.44.0) (2024.6.1)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio-client==1.3.0->gradio==4.44.0) (10.4)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio==4.44.0) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio==4.44.0) (1.3.0)\n",
      "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from fastapi<1.0->gradio==4.44.0) (0.47.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\loq\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio==4.44.0) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\loq\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio==4.44.0) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio==4.44.0) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\loq\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio==4.44.0) (3.13.1)\n",
      "Requirement already satisfied: requests in c:\\users\\loq\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio==4.44.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio==4.44.0) (4.66.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio==4.44.0) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio==4.44.0) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio==4.44.0) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio==4.44.0) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio==4.44.0) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio==4.44.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio==4.44.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio==4.44.0) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from pydantic>=2.0->gradio==4.44.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from pydantic>=2.0->gradio==4.44.0) (2.20.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\loq\\appdata\\roaming\\python\\python312\\site-packages (from typer<1.0,>=0.12->gradio==4.44.0) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio==4.44.0) (1.5.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio==4.44.0) (13.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\loq\\appdata\\roaming\\python\\python312\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio==4.44.0) (0.4.6)\n",
      "Collecting numpy<3.0,>=1.0 (from gradio==4.44.0)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==4.44.0) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==4.44.0) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\loq\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==4.44.0) (2.19.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->gradio==4.44.0) (3.3.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio==4.44.0) (0.1.0)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.6\n",
      "    Uninstalling numpy-2.2.6:\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "Successfully installed numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python\n",
    "%pip install gradio==4.44.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fdf98b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Gradio Blocks instance: 1 backend functions\n",
       "-------------------------------------------\n",
       "fn_index=0\n",
       " inputs:\n",
       " |-<gradio.components.image.Image object at 0x000001A76020F4D0>\n",
       " outputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x000001A7601627B0>\n",
       " |-<gradio.components.slider.Slider object at 0x000001A75CC00740>\n",
       " |-<gradio.components.textbox.Textbox object at 0x000001A75A0D9DF0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import io, base64, cv2, gradio as gr\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "# Reload model (for safety if you restart kernel cells)\n",
    "try:\n",
    "    mdl = tf.keras.models.load_model(MODEL_PATH.as_posix())\n",
    "    with open(LABELS_PATH, \"r\") as f:\n",
    "        idx = json.load(f)\n",
    "    inv = {v:k for k,v in idx.items()}\n",
    "    class1 = inv.get(1, None)\n",
    "    model_loaded = True\n",
    "except Exception as e:\n",
    "    print(\"[WARN] Failed to load model, using Mock Mode:\", e)\n",
    "    mdl = None\n",
    "    class1 = None\n",
    "    model_loaded = False\n",
    "\n",
    "THRESH = float(globals().get(\"best_th\", 0.5))  # pick the suggested threshold if available\n",
    "\n",
    "def preprocess_pil(img: Image.Image, size=(128,128)):\n",
    "    img = img.convert(\"RGB\").resize(size)\n",
    "    arr = np.asarray(img).astype(\"float32\") / 255.0\n",
    "    arr = np.expand_dims(arr, axis=0)\n",
    "    return arr\n",
    "\n",
    "def mock_fake_probability(img: Image.Image) -> float:\n",
    "    try:\n",
    "        img_cv = cv2.cvtColor(np.array(img.convert(\"RGB\")), cv2.COLOR_RGB2BGR)\n",
    "        var_lap = cv2.Laplacian(img_cv, cv2.CV_64F).var()\n",
    "    except Exception:\n",
    "        var_lap = 50.0\n",
    "    edges = img.convert(\"L\").filter(ImageFilter.FIND_EDGES)\n",
    "    edge_mean = np.array(edges).mean()\n",
    "    sharp = np.tanh(var_lap / 200.0)\n",
    "    edginess = np.tanh(edge_mean / 64.0)\n",
    "    score = 0.6 * (1 - sharp) + 0.4 * (1 - edginess)\n",
    "    return float(np.clip(score, 0, 1))\n",
    "\n",
    "def predict_image(pil_image):\n",
    "    if pil_image is None:\n",
    "        return \"No image\", 0.0, \"Provide an image.\"\n",
    "    if model_loaded and mdl is not None:\n",
    "        size = mdl.inputs[0].shape[1:3]\n",
    "        size = (int(size[0]), int(size[1]))\n",
    "        arr = preprocess_pil(pil_image, size=size)\n",
    "        p1 = float(mdl.predict(arr, verbose=0)[0][0])  # prob of class index 1\n",
    "        if class1 and class1.lower() == \"real\":\n",
    "            p_fake = 1.0 - p1\n",
    "        else:\n",
    "            p_fake = p1\n",
    "    else:\n",
    "        p_fake = mock_fake_probability(pil_image)\n",
    "\n",
    "    label = \"FAKE\" if p_fake >= THRESH else \"REAL\"\n",
    "    note = \"Using trained model\" if model_loaded else \"Using Mock Mode (demo heuristic)\"\n",
    "    return label, p_fake, note\n",
    "\n",
    "title = \"Deepfake Detector (Notebook Demo)\"\n",
    "desc = \"Upload an image or use webcam. The app returns a label and a fake probability. Shows demo heuristic if model isn't loaded.\"\n",
    "\n",
    "with gr.Blocks(title=title) as demo:\n",
    "    gr.Markdown(f\"\"\"### {title}\n",
    "{desc}\n",
    "\n",
    "**Model loaded:** {model_loaded}  \n",
    "**Threshold:** {THRESH:.2f}\"\"\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            img_in = gr.Image(type=\"pil\", label=\"Input image\", sources=[\"upload\", \"webcam\"])\n",
    "            btn = gr.Button(\"Analyze\")\n",
    "        with gr.Column():\n",
    "            out_label = gr.Textbox(label=\"Prediction\", interactive=False)\n",
    "            out_prob = gr.Slider(0, 1, value=0.0, step=0.001, label=\"Fake probability\", interactive=False)\n",
    "            out_note = gr.Textbox(label=\"Note\", interactive=False)\n",
    "    btn.click(fn=predict_image, inputs=img_in, outputs=[out_label, out_prob, out_note])\n",
    "\n",
    "demo\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
