{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbae7e72",
   "metadata": {},
   "source": [
    "\n",
    "# 🧪 Deepfake Detection — Jupyter Notebook (Keras + Gradio)\n",
    "\n",
    "This notebook lets you **train** and **demo** a Deepfake Detector end‑to‑end:\n",
    "\n",
    "- ✅ Dataset loaders (train/val split via `flow_from_directory`)\n",
    "- ✅ Choice of **Simple CNN** or **EfficientNetB0** (transfer learning)\n",
    "- ✅ Saves `models/deepfake_detector_keras.h5` and `models/labels.json`\n",
    "- ✅ Quick evaluation & **threshold** suggestion\n",
    "- ✅ **Gradio UI** for uploads and **webcam** (if supported)\n",
    "- ✅ **Mock Mode** fallback if no model is loaded\n",
    "\n",
    "> **Dataset format (binary classes):**\n",
    ">\n",
    "> ```\n",
    "> data/dataset/\n",
    "> ├── real/\n",
    "> └── fake/\n",
    "> ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87870e72",
   "metadata": {},
   "source": [
    "## 1) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e8cfaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.19.0\n",
      "GPU Available: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# If needed, install packages (uncomment as necessary)\n",
    "# %pip install tensorflow==2.15.0 pillow numpy opencv-python-headless gradio==4.44.0 scikit-learn\n",
    "\n",
    "import os, json, math, time, pathlib, typing, warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fff575",
   "metadata": {},
   "source": [
    "## 2) Configure paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc497dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR: d:\\Mtech\\Research paper\\DeepFake Detection\\Draft 4\n",
      "DATA_DIR exists: True\n",
      "MODEL_DIR: d:\\Mtech\\Research paper\\DeepFake Detection\\Draft 4\\models\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Change these if your structure differs\n",
    "BASE_DIR = Path.cwd()\n",
    "DATA_DIR = BASE_DIR / \"data\" / \"dataset\"   # expects subfolders: real/, fake/\n",
    "MODEL_DIR = BASE_DIR / \"models\"\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_PATH = MODEL_DIR / \"deepfake_detector_keras.h5\"\n",
    "LABELS_PATH = MODEL_DIR / \"labels.json\"\n",
    "\n",
    "IMG_SIZE = (128, 128)   # can override to (224,224) for EfficientNet\n",
    "BATCH = 64\n",
    "VAL_SPLIT = 0.2\n",
    "EPOCHS = 3              # start with 8–15, tune later\n",
    "\n",
    "print(\"BASE_DIR:\", BASE_DIR)\n",
    "print(\"DATA_DIR exists:\", DATA_DIR.exists())\n",
    "print(\"MODEL_DIR:\", MODEL_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a612286",
   "metadata": {},
   "source": [
    "## 3) Data generators (train/val split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deed1d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16002 images belonging to 2 classes.\n",
      "Found 4000 images belonging to 2 classes.\n",
      "Saved class indices: {'Fake': 0, 'Real': 1}\n",
      "labels.json: d:\\Mtech\\Research paper\\DeepFake Detection\\Draft 4\\models\\labels.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not DATA_DIR.exists():\n",
    "    raise SystemExit(f\"Dataset folder not found: {DATA_DIR}. Put images under real/ and fake/ subfolders.\")\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1/255.0,\n",
    "    validation_split=VAL_SPLIT,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.02,\n",
    "    height_shift_range=0.02,\n",
    "    zoom_range=0.5,\n",
    ")\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    DATA_DIR.as_posix(),\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"training\",\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_gen = train_datagen.flow_from_directory(\n",
    "    DATA_DIR.as_posix(),\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"validation\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Save class indices for later (UI needs to know which class is index 1)\n",
    "with open(LABELS_PATH, \"w\") as f:\n",
    "    json.dump(train_gen.class_indices, f)\n",
    "print(\"Saved class indices:\", train_gen.class_indices)\n",
    "print(\"labels.json:\", LABELS_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea13185",
   "metadata": {},
   "source": [
    "## 4) Choose model: Simple CNN or EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a71f24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,569</span> (396.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101,569\u001b[0m (396.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,569</span> (396.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,569\u001b[0m (396.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "USE_EFFICIENTNET = False   # <-- flip to True for transfer learning\n",
    "\n",
    "def build_simple_cnn(input_shape=(128,128,3)):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\")(inputs)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = models.Model(inputs, outputs)\n",
    "    model.compile(optimizer=optimizers.Adam(1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def build_efficientnet_b0(input_shape=(224,224,3)):\n",
    "    from tensorflow.keras.applications import EfficientNetB0\n",
    "    from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "    base = EfficientNetB0(include_top=False, input_shape=input_shape, weights=\"imagenet\")\n",
    "    base.trainable = False  # freeze first stage\n",
    "\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = preprocess_input(inputs)\n",
    "    x = base(x, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.35)(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = models.Model(inputs, outputs)\n",
    "    model.compile(optimizer=optimizers.Adam(1e-3), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# pick model\n",
    "if USE_EFFICIENTNET:\n",
    "    IMG_SIZE = (224,224)\n",
    "    # re-build generators with new image size\n",
    "    train_gen = train_datagen.flow_from_directory(\n",
    "        DATA_DIR.as_posix(),\n",
    "        target_size=IMG_SIZE, batch_size=BATCH, class_mode=\"binary\", subset=\"training\", shuffle=True\n",
    "    )\n",
    "    val_gen = train_datagen.flow_from_directory(\n",
    "        DATA_DIR.as_posix(),\n",
    "        target_size=IMG_SIZE, batch_size=BATCH, class_mode=\"binary\", subset=\"validation\", shuffle=False\n",
    "    )\n",
    "    model = build_efficientnet_b0(input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "else:\n",
    "    model = build_simple_cnn(input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f020cb2",
   "metadata": {},
   "source": [
    "## 5) Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9880549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862ms/step - accuracy: 0.5281 - loss: 0.6914"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 1s/step - accuracy: 0.5296 - loss: 0.6913 - val_accuracy: 0.5203 - val_loss: 0.6911\n",
      "Epoch 2/3\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step - accuracy: 0.5414 - loss: 0.6893"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 404ms/step - accuracy: 0.5451 - loss: 0.6871 - val_accuracy: 0.5370 - val_loss: 0.6911\n",
      "Epoch 3/3\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - accuracy: 0.5484 - loss: 0.6873"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 422ms/step - accuracy: 0.5594 - loss: 0.6834 - val_accuracy: 0.6430 - val_loss: 0.6631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: d:\\Mtech\\Research paper\\DeepFake Detection\\Draft 4\\models\\deepfake_detector_keras.h5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ckpt = callbacks.ModelCheckpoint(MODEL_PATH.as_posix(), monitor=\"val_accuracy\", save_best_only=True, mode=\"max\")\n",
    "es = callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=3, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[ckpt, es],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.save(MODEL_PATH.as_posix())\n",
    "print(\"Saved model to:\", MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ed3cc7",
   "metadata": {},
   "source": [
    "## 6) Quick evaluation & threshold suggestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adb3e7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class index 1 is: Real\n",
      "Suggested threshold: 0.46 (F1=0.350)\n",
      "[[ 157 1843]\n",
      " [ 435 1565]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.27      0.08      0.12      2000\n",
      "        Real       0.46      0.78      0.58      2000\n",
      "\n",
      "    accuracy                           0.43      4000\n",
      "   macro avg       0.36      0.43      0.35      4000\n",
      "weighted avg       0.36      0.43      0.35      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "val_gen.reset()\n",
    "p1 = model.predict(val_gen, verbose=0).ravel()  # prob of class index 1\n",
    "y_true = val_gen.classes\n",
    "\n",
    "# Load mapping and infer which class is index 1\n",
    "with open(LABELS_PATH, \"r\") as f:\n",
    "    idx = json.load(f)  # e.g., {'fake': 0, 'real': 1}\n",
    "inv = {v:k for k,v in idx.items()}\n",
    "class1 = inv.get(1, None)\n",
    "print(\"Class index 1 is:\", class1)\n",
    "\n",
    "# p(fake) depends on what class 1 represents\n",
    "if class1 and class1.lower() == \"real\":\n",
    "    p_fake = 1.0 - p1\n",
    "else:\n",
    "    p_fake = p1  # class 1 is 'fake' or unknown mapping\n",
    "\n",
    "ths = np.linspace(0.3, 0.7, 41)\n",
    "best_f1, best_th = -1, 0.5\n",
    "for th in ths:\n",
    "    y_hat = (p_fake >= th).astype(int)\n",
    "    f1 = f1_score(y_true, y_hat, average=\"macro\")\n",
    "    if f1 > best_f1:\n",
    "        best_f1, best_th = f1, th\n",
    "\n",
    "print(f\"Suggested threshold: {best_th:.2f} (F1={best_f1:.3f})\")\n",
    "print(confusion_matrix(y_true, (p_fake >= best_th).astype(int)))\n",
    "print(classification_report(y_true, (p_fake >= best_th).astype(int), target_names=[inv.get(0,'class0'), inv.get(1,'class1')]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea219b0",
   "metadata": {},
   "source": [
    "## 7) Gradio demo (upload & webcam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "989bf1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\loq\\anaconda3\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from opencv-python) (2.2.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting gradio==4.44.0\n",
      "  Downloading gradio-4.44.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio==4.44.0)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (4.2.0)\n",
      "Collecting fastapi<1.0 (from gradio==4.44.0)\n",
      "  Downloading fastapi-0.116.1-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting ffmpy (from gradio==4.44.0)\n",
      "  Downloading ffmpy-0.6.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio-client==1.3.0 (from gradio==4.44.0)\n",
      "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (0.27.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (0.29.3)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (6.5.2)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\loq\\appdata\\roaming\\python\\python312\\site-packages (from gradio==4.44.0) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\loq\\appdata\\roaming\\python\\python312\\site-packages (from gradio==4.44.0) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (3.9.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (2.2.6)\n",
      "Collecting orjson~=3.0 (from gradio==4.44.0)\n",
      "  Downloading orjson-3.11.1-cp312-cp312-win_amd64.whl.metadata (43 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (24.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (2.2.2)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (10.4.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (2.8.2)\n",
      "Collecting pydub (from gradio==4.44.0)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.9 (from gradio==4.44.0)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (6.0.1)\n",
      "Collecting ruff>=0.2.2 (from gradio==4.44.0)\n",
      "  Downloading ruff-0.12.8-py3-none-win_amd64.whl.metadata (26 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio==4.44.0)\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio==4.44.0)\n",
      "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio==4.44.0)\n",
      "  Downloading typer-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio==4.44.0) (4.11.0)\n",
      "Collecting urllib3~=2.0 (from gradio==4.44.0)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting uvicorn>=0.14.0 (from gradio==4.44.0)\n",
      "  Downloading uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio-client==1.3.0->gradio==4.44.0) (2024.6.1)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from gradio-client==1.3.0->gradio==4.44.0) (10.4)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio==4.44.0) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio==4.44.0) (1.3.0)\n",
      "Collecting starlette<0.48.0,>=0.40.0 (from fastapi<1.0->gradio==4.44.0)\n",
      "  Downloading starlette-0.47.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\loq\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio==4.44.0) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\loq\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio==4.44.0) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio==4.44.0) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\loq\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio==4.44.0) (3.13.1)\n",
      "Requirement already satisfied: requests in c:\\users\\loq\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio==4.44.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio==4.44.0) (4.66.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio==4.44.0) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio==4.44.0) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio==4.44.0) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio==4.44.0) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio==4.44.0) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio==4.44.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio==4.44.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio==4.44.0) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from pydantic>=2.0->gradio==4.44.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from pydantic>=2.0->gradio==4.44.0) (2.20.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\loq\\appdata\\roaming\\python\\python312\\site-packages (from typer<1.0,>=0.12->gradio==4.44.0) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio==4.44.0) (1.5.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio==4.44.0) (13.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\loq\\appdata\\roaming\\python\\python312\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio==4.44.0) (0.4.6)\n",
      "Collecting numpy<3.0,>=1.0 (from gradio==4.44.0)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==4.44.0) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==4.44.0) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\loq\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==4.44.0) (2.19.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->gradio==4.44.0) (3.3.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\loq\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio==4.44.0) (0.1.0)\n",
      "Downloading gradio-4.44.0-py3-none-any.whl (18.1 MB)\n",
      "   ---------------------------------------- 0.0/18.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/18.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/18.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/18.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/18.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/18.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/18.1 MB 452.8 kB/s eta 0:00:39\n",
      "   - -------------------------------------- 0.5/18.1 MB 452.8 kB/s eta 0:00:39\n",
      "   - -------------------------------------- 0.8/18.1 MB 524.3 kB/s eta 0:00:33\n",
      "   - -------------------------------------- 0.8/18.1 MB 524.3 kB/s eta 0:00:33\n",
      "   - -------------------------------------- 0.8/18.1 MB 524.3 kB/s eta 0:00:33\n",
      "   - -------------------------------------- 0.8/18.1 MB 524.3 kB/s eta 0:00:33\n",
      "   - -------------------------------------- 0.8/18.1 MB 524.3 kB/s eta 0:00:33\n",
      "   - -------------------------------------- 0.8/18.1 MB 524.3 kB/s eta 0:00:33\n",
      "   - -------------------------------------- 0.8/18.1 MB 524.3 kB/s eta 0:00:33\n",
      "   -- ------------------------------------- 1.0/18.1 MB 320.5 kB/s eta 0:00:54\n",
      "   -- ------------------------------------- 1.0/18.1 MB 320.5 kB/s eta 0:00:54\n",
      "   -- ------------------------------------- 1.0/18.1 MB 320.5 kB/s eta 0:00:54\n",
      "   -- ------------------------------------- 1.0/18.1 MB 320.5 kB/s eta 0:00:54\n",
      "   -- ------------------------------------- 1.0/18.1 MB 320.5 kB/s eta 0:00:54\n",
      "   -- ------------------------------------- 1.0/18.1 MB 320.5 kB/s eta 0:00:54\n",
      "   -- ------------------------------------- 1.3/18.1 MB 278.4 kB/s eta 0:01:01\n",
      "   -- ------------------------------------- 1.3/18.1 MB 278.4 kB/s eta 0:01:01\n",
      "   -- ------------------------------------- 1.3/18.1 MB 278.4 kB/s eta 0:01:01\n",
      "   -- ------------------------------------- 1.3/18.1 MB 278.4 kB/s eta 0:01:01\n",
      "   --- ------------------------------------ 1.6/18.1 MB 295.3 kB/s eta 0:00:56\n",
      "   --- ------------------------------------ 1.6/18.1 MB 295.3 kB/s eta 0:00:56\n",
      "   ---- ----------------------------------- 1.8/18.1 MB 311.6 kB/s eta 0:00:53\n",
      "   ---- ----------------------------------- 1.8/18.1 MB 311.6 kB/s eta 0:00:53\n",
      "   ---- ----------------------------------- 1.8/18.1 MB 311.6 kB/s eta 0:00:53\n",
      "   ---- ----------------------------------- 1.8/18.1 MB 311.6 kB/s eta 0:00:53\n",
      "   ---- ----------------------------------- 2.1/18.1 MB 322.6 kB/s eta 0:00:50\n",
      "   ---- ----------------------------------- 2.1/18.1 MB 322.6 kB/s eta 0:00:50\n",
      "   ----- ---------------------------------- 2.4/18.1 MB 334.7 kB/s eta 0:00:47\n",
      "   ----- ---------------------------------- 2.4/18.1 MB 334.7 kB/s eta 0:00:47\n",
      "   ----- ---------------------------------- 2.4/18.1 MB 334.7 kB/s eta 0:00:47\n",
      "   ----- ---------------------------------- 2.6/18.1 MB 347.9 kB/s eta 0:00:45\n",
      "   ----- ---------------------------------- 2.6/18.1 MB 347.9 kB/s eta 0:00:45\n",
      "   ------ --------------------------------- 2.9/18.1 MB 364.7 kB/s eta 0:00:42\n",
      "   ------ --------------------------------- 3.1/18.1 MB 382.8 kB/s eta 0:00:39\n",
      "   ------ --------------------------------- 3.1/18.1 MB 382.8 kB/s eta 0:00:39\n",
      "   ------- -------------------------------- 3.4/18.1 MB 402.6 kB/s eta 0:00:37\n",
      "   -------- ------------------------------- 3.7/18.1 MB 424.3 kB/s eta 0:00:34\n",
      "   -------- ------------------------------- 3.9/18.1 MB 446.5 kB/s eta 0:00:32\n",
      "   --------- ------------------------------ 4.5/18.1 MB 488.9 kB/s eta 0:00:28\n",
      "   ---------- ----------------------------- 4.7/18.1 MB 512.0 kB/s eta 0:00:27\n",
      "   ----------- ---------------------------- 5.2/18.1 MB 555.3 kB/s eta 0:00:24\n",
      "   ------------ --------------------------- 5.5/18.1 MB 578.5 kB/s eta 0:00:22\n",
      "   ------------- -------------------------- 6.0/18.1 MB 616.1 kB/s eta 0:00:20\n",
      "   -------------- ------------------------- 6.6/18.1 MB 654.7 kB/s eta 0:00:18\n",
      "   --------------- ------------------------ 6.8/18.1 MB 672.2 kB/s eta 0:00:17\n",
      "   ---------------- ----------------------- 7.3/18.1 MB 705.5 kB/s eta 0:00:16\n",
      "   ----------------- ---------------------- 7.9/18.1 MB 739.4 kB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 8.1/18.1 MB 751.2 kB/s eta 0:00:14\n",
      "   ------------------- -------------------- 8.7/18.1 MB 786.0 kB/s eta 0:00:12\n",
      "   -------------------- ------------------- 9.2/18.1 MB 819.6 kB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 10.2/18.1 MB 896.6 kB/s eta 0:00:09\n",
      "   ------------------------ --------------- 11.0/18.1 MB 951.4 kB/s eta 0:00:08\n",
      "   -------------------------- ------------- 11.8/18.1 MB 1.0 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 12.6/18.1 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 13.9/18.1 MB 1.1 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 15.2/18.1 MB 1.2 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 15.7/18.1 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 16.5/18.1 MB 1.3 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 17.6/18.1 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.1/18.1 MB 1.4 MB/s eta 0:00:00\n",
      "Downloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
      "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading fastapi-0.116.1-py3-none-any.whl (95 kB)\n",
      "Downloading orjson-3.11.1-cp312-cp312-win_amd64.whl (131 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ruff-0.12.8-py3-none-win_amd64.whl (12.7 MB)\n",
      "   ---------------------------------------- 0.0/12.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/12.7 MB 7.1 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.9/12.7 MB 7.0 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.0/12.7 MB 7.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.3/12.7 MB 8.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.4/12.7 MB 8.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.1/12.7 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.7/12.7 MB 9.4 MB/s eta 0:00:00\n",
      "Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading uvicorn-0.35.0-py3-none-any.whl (66 kB)\n",
      "Downloading ffmpy-0.6.1-py3-none-any.whl (5.5 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "   ---------------------------------------- 0.0/15.5 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 2.9/15.5 MB 15.2 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 3.7/15.5 MB 12.8 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 6.6/15.5 MB 10.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 10.0/15.5 MB 12.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.6/15.5 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.4/15.5 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.5/15.5 MB 10.8 MB/s eta 0:00:00\n",
      "Downloading starlette-0.47.2-py3-none-any.whl (72 kB)\n",
      "Installing collected packages: pydub, urllib3, tomlkit, semantic-version, ruff, python-multipart, orjson, numpy, ffmpy, aiofiles, uvicorn, starlette, typer, fastapi, gradio-client, gradio\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.20\n",
      "    Uninstalling urllib3-1.26.20:\n",
      "      Successfully uninstalled urllib3-1.26.20\n",
      "  Attempting uninstall: tomlkit\n",
      "    Found existing installation: tomlkit 0.11.1\n",
      "    Uninstalling tomlkit-0.11.1:\n",
      "      Successfully uninstalled tomlkit-0.11.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.6\n",
      "    Uninstalling numpy-2.2.6:\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "  Attempting uninstall: typer\n",
      "    Found existing installation: typer 0.9.0\n",
      "    Uninstalling typer-0.9.0:\n",
      "      Successfully uninstalled typer-0.9.0\n",
      "Successfully installed aiofiles-23.2.1 fastapi-0.116.1 ffmpy-0.6.1 gradio-4.44.0 gradio-client-1.3.0 numpy-1.26.4 orjson-3.11.1 pydub-0.25.1 python-multipart-0.0.20 ruff-0.12.8 semantic-version-2.10.0 starlette-0.47.2 tomlkit-0.12.0 typer-0.16.0 urllib3-2.5.0 uvicorn-0.35.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "pyppeteer 2.0.0 requires pyee<12.0.0,>=11.0.0, but you have pyee 12.0.0 which is incompatible.\n",
      "pyppeteer 2.0.0 requires urllib3<2.0.0,>=1.25.8, but you have urllib3 2.5.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python\n",
    "%pip install gradio==4.44.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fdf98b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Gradio Blocks instance: 1 backend functions\n",
       "-------------------------------------------\n",
       "fn_index=0\n",
       " inputs:\n",
       " |-<gradio.components.image.Image object at 0x000001C077E234D0>\n",
       " outputs:\n",
       " |-<gradio.components.textbox.Textbox object at 0x000001C05601C530>\n",
       " |-<gradio.components.slider.Slider object at 0x000001C077F2FBC0>\n",
       " |-<gradio.components.textbox.Textbox object at 0x000001C077F5CE30>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import io, base64, cv2, gradio as gr\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "# Reload model (for safety if you restart kernel cells)\n",
    "try:\n",
    "    mdl = tf.keras.models.load_model(MODEL_PATH.as_posix())\n",
    "    with open(LABELS_PATH, \"r\") as f:\n",
    "        idx = json.load(f)\n",
    "    inv = {v:k for k,v in idx.items()}\n",
    "    class1 = inv.get(1, None)\n",
    "    model_loaded = True\n",
    "except Exception as e:\n",
    "    print(\"[WARN] Failed to load model, using Mock Mode:\", e)\n",
    "    mdl = None\n",
    "    class1 = None\n",
    "    model_loaded = False\n",
    "\n",
    "THRESH = float(globals().get(\"best_th\", 0.5))  # pick the suggested threshold if available\n",
    "\n",
    "def preprocess_pil(img: Image.Image, size=(128,128)):\n",
    "    img = img.convert(\"RGB\").resize(size)\n",
    "    arr = np.asarray(img).astype(\"float32\") / 255.0\n",
    "    arr = np.expand_dims(arr, axis=0)\n",
    "    return arr\n",
    "\n",
    "def mock_fake_probability(img: Image.Image) -> float:\n",
    "    try:\n",
    "        img_cv = cv2.cvtColor(np.array(img.convert(\"RGB\")), cv2.COLOR_RGB2BGR)\n",
    "        var_lap = cv2.Laplacian(img_cv, cv2.CV_64F).var()\n",
    "    except Exception:\n",
    "        var_lap = 50.0\n",
    "    edges = img.convert(\"L\").filter(ImageFilter.FIND_EDGES)\n",
    "    edge_mean = np.array(edges).mean()\n",
    "    sharp = np.tanh(var_lap / 200.0)\n",
    "    edginess = np.tanh(edge_mean / 64.0)\n",
    "    score = 0.6 * (1 - sharp) + 0.4 * (1 - edginess)\n",
    "    return float(np.clip(score, 0, 1))\n",
    "\n",
    "def predict_image(pil_image):\n",
    "    if pil_image is None:\n",
    "        return \"No image\", 0.0, \"Provide an image.\"\n",
    "    if model_loaded and mdl is not None:\n",
    "        size = mdl.inputs[0].shape[1:3]\n",
    "        size = (int(size[0]), int(size[1]))\n",
    "        arr = preprocess_pil(pil_image, size=size)\n",
    "        p1 = float(mdl.predict(arr, verbose=0)[0][0])  # prob of class index 1\n",
    "        if class1 and class1.lower() == \"real\":\n",
    "            p_fake = 1.0 - p1\n",
    "        else:\n",
    "            p_fake = p1\n",
    "    else:\n",
    "        p_fake = mock_fake_probability(pil_image)\n",
    "\n",
    "    label = \"FAKE\" if p_fake >= THRESH else \"REAL\"\n",
    "    note = \"Using trained model\" if model_loaded else \"Using Mock Mode (demo heuristic)\"\n",
    "    return label, p_fake, note\n",
    "\n",
    "title = \"Deepfake Detector (Notebook Demo)\"\n",
    "desc = \"Upload an image or use webcam. The app returns a label and a fake probability. Shows demo heuristic if model isn't loaded.\"\n",
    "\n",
    "with gr.Blocks(title=title) as demo:\n",
    "    gr.Markdown(f\"\"\"### {title}\n",
    "{desc}\n",
    "\n",
    "**Model loaded:** {model_loaded}  \n",
    "**Threshold:** {THRESH:.2f}\"\"\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            img_in = gr.Image(type=\"pil\", label=\"Input image\", sources=[\"upload\", \"webcam\"])\n",
    "            btn = gr.Button(\"Analyze\")\n",
    "        with gr.Column():\n",
    "            out_label = gr.Textbox(label=\"Prediction\", interactive=False)\n",
    "            out_prob = gr.Slider(0, 1, value=0.0, step=0.001, label=\"Fake probability\", interactive=False)\n",
    "            out_note = gr.Textbox(label=\"Note\", interactive=False)\n",
    "    btn.click(fn=predict_image, inputs=img_in, outputs=[out_label, out_prob, out_note])\n",
    "\n",
    "demo\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
